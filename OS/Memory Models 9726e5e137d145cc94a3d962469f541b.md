# Memory Models

Created: May 28, 2022 5:16 PM

# 硬件内存模型

1. 之前单线程程序的年代，使程序运行更快就什么都不干，等着下一代硬件的优化 和下一代编译器。过去信奉：有效的优化 不会改变程序的行为，即除了运行的更快，有效的程序在优化前后行为一致
2. 后来，硬件工程师在单处理器上没法精进了，创造了多核CPU，并且操作系统用线程的抽象来给程序员暴露硬件的并行性。
    1. 有效的程序 ＋ 有效的优化，在多处理器上会得到有效的程序吗？

```
// Thread 1           // Thread 2
x = 1;                while(done == 0) { /* loop */ }
done = 1;             print(x);
```

1. 如上程序，如果逐行翻译为汇编语言（不做编译器优化），在x86上print x =1，而在ARM/POWER多处理器上，会print 0
    1. 同样，不论底层硬件是什么，编译器优化都可能世道print 0，甚至无限while
    2. 而这里主要的问题就在于：数据存储在内存中的可见性 和 一致性（如上，thread1 的x在在thread2 没看到的时候，还认为是0）

---

### 内存模型=内存一致性模型

- 内存模型的目标是定义硬件保证程序员写的汇编代码。因此，编译器的处理并不包含。

### **Sequential Consistency - 顺序一致性**

- 究竟什么是顺序一致性？Leslie Lamport's 1979 paper
    - the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.
    - 每个处理器执行的顺序，产生的操作序列按照程序执行的顺序
- 今天的编程语言保证的顺序一致性，多个线程的执行按照唯一可能的顺序执行
    - 多线程的执行按照一些顺序简单交互，不会出现重排序
    - 一种理想的模型，对程序员来说也是最自然的考虑方式

```
// Thread 1           // Thread 2
x = 1                 r1 = y
y = 1                 r2 = x
```

- 在顺序一致性的情况下？可能看到y=1 x=0 吗？显然不会，只要r1读到了y，根据顺序一致性，线程一定是按照唯一的顺序执行，也就是x也应该被thread2看到，要么00，要么11 要么01
- 实现顺序一致性的模型，将所有的处理器直接访问相同的共享内存，这种一次一使用的共享内存，保证了所有的内存访问的执行按照一种顺序

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled.png)

---

- 但是！放弃严格顺序一致性，可以使得硬件执行程序更快，因此所有的现代硬件都不保证顺序一致性。

### x86的TSO（total store order）

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%201.png)

- 所有处理器仍然连接到一个共享内存，但是每个处理器 都将write加入队列（FIFO），排序写入shared memory。当write在队列中刷到shared memory中的时候，处理器依然工作。
- 每个read 先查自己的write queue，然后查shared memory，但是处理器的write 队列不可见
1. 导致，可以处理器看到自己的写 早于 其他处理器。
2. 但是store的顺序 在所有处理器之间达成一致
3. 一个write到达了shared memory，所有处理器都可见（除非自己buffered write里有）
- 之前的测试，在这种模型下，仍然不会发生 1 0  。线程1的x写 一定会早于y的写，因此线程2的read 也不会先read到新的y

---

- 两个模型不同的例子

```cpp
// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x
```

- 这个例子中，r1 r2 可能都是00吗？在顺序一致性模型中，不可能，两个read都从内存中读到。而在TSO中，r1 r2都可能读到还没写到 shared memory的旧值
- 为了修复这种情况，没有顺序一致性的硬件，都会支持显式的指令，比如 barriers 和 fence 来保证控制顺序，也就是内存可见性。保证在两个read之前的write都要刷到共享内存中中

```
// Thread 1           // Thread 2
x = 1                 y = 1
barrier               barrier
r1 = y                r2 = x
```

- 屏障也只是：一种在程序的关键时刻强制执行顺序一致行为的方法。

### ARM的宽松内存模型 Relaxed Memory Model

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%202.png)

- 每个处理器，读写它自己的完整内存拷贝，并且每个写入都独立地传播到其他处理器，并且在写入传播时允许重新排序。
    - read可以延迟到稍后的写入之后。每个线程甚至可以read发生在另一个线程的后write
    - 单个处理器对写入的重新排序意味着 之前 线程 1 的写入可能不会被其他线程以相同的顺序观察到。不同的线程可能会以不同的顺序 read到不同的写入
    - 写入以任何顺序在内存之间传播。不保证到达主存的顺序

```
// Thread 1    // Thread 2    // Thread 3    // Thread 4
// Can Thread 3 see x = 1 before x = 2 while Thread 4 sees the reverse? No
x = 1          x = 2          r1 = x         r3 = x
                              r2 = x         r4 = x
```

- 宽松内存模型 会保证：*coherence*
    - 连贯性：系统中的线程必须就写入单个内存位置的总顺序达成一致。 也就是说，线程必须同意哪些写入覆盖其他写入。

### 弱排序和无数据竞争的顺序一致性

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%203.png)

- 此时 单线程没有数据竞争，write happens before read

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%204.png)

- 线程2 要 write x，这和线程1 的读写 都 冲突。
    - （每个race 至少包括一个write）

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%205.png)

- 通过添加 同步操作，强制 前后没有冲突。此时 thread2 和thread1 其实就没有并行了。

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%206.png)

- 如果线程2 是个read操作，之和 thread1 的write 有数据竞争，那么两个read 还是可以并行的

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%207.png)

![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%208.png)

- 事实上，还可以通过 间接同步，来使得程序顺序执行，但是也可能用错。线程1 3 之间是有data race的
- 现在的硬件支持可以保证，只要程序当中没有数据竞争，那么程序的执行就会像 顺序一致性一样。
    - 其实就是 软件程序自己把该同步的同步，不该同步的、没有依赖关系的数据，被硬件怎么重排序都没有影响

# 编程语言的内存模型

- 并行程序在线程之间可以依赖共享内存的什么行为？

```
// Thread 1           // Thread 2
x = 1;                while(done == 0) { /* loop */ }
done = 1;             print(x);
```

- 经典例子。来看看主流编程语言都会有什么rule保证
    - 对于 ordinary val，thread2 的loop可能永远不会停下，因为编译器优化会在第一次使用done的时候，加载到CPU的寄存器上，然后一直reuse，即使线程1执行完，线程二也不会注意到memory的数据被修改
    - 即使线程2读到了 done ==1，编译器优化（基于启发式优化）也经常会重排序程序的读写，因此x=1 可能会被重排序到done的后边，也可能printx 被排序到loop前边
- 如何fix 这个程序？编程语言都提供了atomic或类似的操作，将done 声明为atomic之后：
    - 编译器会保证，x的写完成，而且是其他线程可见的，并且是在写done之前
    - 线程二 必须在loop中每次read 都从mem中读，且读x 必须在读done之后
    - 编译器也要执行必要的操作，来禁用硬件对这些情况的优化
- 现代编译器的优化会使得程序产生很多可能的结果，不论底层硬件的内存模型是什么
- 今天的硬件普遍会保证 DRF-SC（即，没有数据竞争，就是顺序一致性的）
    - 为了这个，硬件需要提供 同步指令，比如riscv 的 test and set 用来实现fast path的spinlock
    - 程序可以使用这些指令 来创建 happens before 关系，保证没有数据竞争，就可以实现多处理器之间的并行且是顺序一致的
    - Happens before 是什么？一种关系，表示代码 在一个处理器上运行 和 其他处理器上运行的一种关系，如图。没有 happens before关系的程序，两个时间发生的顺序是不确定的
    
    ![Untitled](Memory%20Models%209726e5e137d145cc94a3d962469f541b/Untitled%209.png)
    

### 编译器和优化

- 编译器可以几乎任意地对内存的普通读取和写入重新排序，只要重新排序不能改变观察到的代码的单线程执行。编译器的内存模型 甚至是所有硬件中基础上 最weak的。
- 之前ARM的宽松内存模型 至少 还可以 保证 连贯性coherence，但是在现代编译过的语言上使用ordinary val 都没法保证

> Litmus Test: CoherenceCan this program see r1 = 1, r2 = 2, r3 = 2, r4 = 1?(Can Thread 3 see x = 1 before x = 2 while Thread 4 sees the reverse?)
> 

```
// Thread 1    // Thread 2    // Thread 3    // Thread 4
x = 1          x = 2          r1 = x         r3 = x
                              r2 = x         r4 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): no.
On ARM/POWER: no.
In any modern compiled language using ordinary variables: yes! //编译器可以把r4的read提前，如下
```

```
// Thread 1    // Thread 2    // Thread 3    // Thread 4
                                             // (reordered)
(1) x = 1                     (2) r1 = x     (3) r4 = x
               (4) x = 2      (5) r2 = x     (6) r3 = x
```

- 编译器能保证什么？DRF-SC，也就是编译器优化不能增加写或读，即使这个优化在单线程场景下有效

### 原始 Java 内存模型 (1996)

- Java是最先尝试给 多线程程序提供 保证的主流语言。
    - 包括 volatile的原子变量：所有的原子变量 读写被要求 在主存上顺序执行，使得在原子变量上的操作 保证顺序一致的行为
    - 原本Java第一版还想指定原始变量的coherence形式，但是至少出现了两处缺陷
- 【atomic 需要 同步】，第一处缺陷：volatile 的原子变量没有同步（导致会出现没有happens before的关系），导致没有处理剩下程序里的竞争，如下程序，即使while一定会从主存read done变量，但是没有保证x不会被reorder到loop前，所有 内存模型还是很weak

```
int x;
volatile int done;

// Thread 1           // Thread 2
x = 1;                while(done == 0) { /* loop */ }
done = 1;             print(x);
```

- 【coherence 和编译优化 不兼容】，早期Java 规定了一旦一个thread 已经读了一个新值，那么就再也不会出现读到old val的情况（看起来没毛病），但是这也禁用了基本的编译优化。
    - 比如如下程序，我们在一个线程中的前后，read  到的p obj的x值都不一样，其实还是发生了read到了一个old val i和一个new val k，那我们究竟应该认为是出错了还是只用k？
    - 对于 同一对象的common subexep ，会被优化为 k = i，这时。。。k重用i其实是用了old val，这显然不对了
    - 无法优化冗余读将使大多数编译器陷入困境，从而使生成的代码变慢。

```
// p and q may or may not point at the same object.
int i = p.x;
// ... maybe another thread writes p.x at this point ...
int j = q.x;
int k = p.x;
```

- 硬件提供 coherence连贯性的保证 要比编译器更简单，硬件可以使用 动态优化，而编译器只能应用静态状态来优化
    - 硬件可以根据给定的内存读取和写入序列中涉及的确切地址调整优化路径。
    - 编译器必须提前 输出 一个无论涉及什么地址和值都是正确的指令序列（其实）。

### New Java 内存模型-2004

- 修了之前的错误想法，Java在5.0的新模型，沿用了DRF-SC，无数据竞争的 Java 程序保证以顺序一致的方式执行。
- 【同步的atomics 和 其他操作】
    - DRF的程序，程序员需要同步操作，来保证 happens before 关系，确保指令不会reorder，确保一个线程不会在另一个线程读取或写入它的同时写入非原子变量。
    - Java 保证的同步操作
        - 线程的创建发生在线程中的第一个操作之前。
        - 互斥锁 m 的解锁发生在 m 的任何后续上锁之前。
        - 对 volatile 变量 v 的写入发生在对 v 的任何后续读取之前。
    - 如何定义 subsequent？
        - Java 定义所有锁定、解锁和 volatile 变量访问的行为就好像它们发生在某种顺序一致的交互中，从而对整个程序中的所有这些操作给出了total ordering。
        - subsequent 是 total ordering中later的部分，subsequent 定义了哪个happens before边沿 被特定执行创建，happens before边沿定义了是否这个特殊的执行存在data race，如果没有data race，那么这个执行行为 就是顺序一致的行为
- 修正过的Java内存模型 ，将不会出现在volatile的变量read时，读取store buffer
    - 在Java中，volatile的变量 x y 读写不能被重排序，如果没有顺序一致性，只有连贯性，那么两个read 可能丢失write，r1 读buffer r2也读buffer，不会到主存读已经写的数据（或者write的数据在buffer 还没写到主存）

> Litmus Test: Store BufferingCan this program see r1 = 0, r2 = 0?
> 

```
// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x

```

> On sequentially consistent hardware: no.On x86 (or other TSO): yes!On ARM/POWER: yes!On Java using volatiles: no.
> 

---

- 【竞态程序的语义】，DRF-SC只保证没有数据竞争的顺序一致行为，在新的Java内存模型中，依然定义了竞态程序的行为，因为一下理由
    - 为了支持Java的通用安全和安全保证
    - 为了使得程序发现错误更容易
    - 为了使得攻击者找到异常更困难
    - 为了使得程序员写的代码更清晰
    - 好笼统...
- 新的模型仍然使用 happens-before 来决定 有数据竞争的读写的结果
- Java 的特定规则是，对于字大小或更小的变量，对变量（或字段）x 的读取必须看到对 x 的单次写入所存储的值。 如果 r 不在 w 之前发生，则读取 r 可以观察到对 x 的写入。 这意味着 r 可以观察在 r 之前发生的写入（但在 r 之前也不会被覆盖），并且它可以观察与 r 竞争的写入。

---

- Happens before 仍然 没有排除 incoherence。Here’s a program with three threads. Let’s assume that Thread 1 and Thread 2 are known to finish before Thread 3 starts.
    - 下面程序还是可能出现r1 r2 是不同的值，如果通过 x =r1 来优化，则与程序原来语义不同

```
// Thread 1           // Thread 2           // Thread 3
lock(m1)              lock(m2)
x = 1                 x = 2
unlock(m1)            unlock(m2)
                                            lock(m1)
                                            lock(m2)
                                            r1 = x
                                            r2 = x
                                            unlock(m2)
                                            unlock(m1)
```

### C++11 内存模型-2011

- 也是收到Java的启发，C++也定义了相似的内存模型
    - C++对有data race的程序不做任何保证（Java还是定义了happens before的行为），
    - C++提供了三种类型的原子量
        - strong sync 顺序一致性（“sequentially consistent”）
        - weak sync 只保证coherence (“acquire/release”, coherence-only)
        - no sync 宽松，重新引入了所有Java关于定义有竞争程序含义的复杂性
    - 结果就是相比Java C++模型更复杂，但是对程序员帮助甚微
- C++ 定义了atomic fence作为 atomic variable的替代，但是用的不多
- 【DRF-SC or 遭殃】对有data race 的程序 C++ 什么都不保证，很容易进入 未定义行为，

```
unsigned i = x;

if (i < 2) {
	foo: ...
	switch (i) {
	case 0:
		...;
		break;
	case 1:
		...;
		break;
	}
}
```

- 假设这个x是个全局变量，编译器可能会将i放在寄存器上，但是如果foo很复杂，可能需要重用i，那么编译器优化可能会在第二次访问switch的i时，重新从全局变量loadx，emmm，这时...x可能就不是0 1 了，如果编译器把swtich 编译为一个计算之后的跳转表（使用x做索引），那么x不是01的地址，可能....就是个异常地址
- 当然，期望一个为单线程世界写的编译器 支持多线程的模型，确实不切实际。对于现代的c和c++编译器 其实 假定没有程序员敢写未定义行为的代码，或者说程序员不该写这样的程序，写出来其实是人的问题
- 【**Acquire/release atomics**】
    - c++提供了对atomic变量的显式 操作（带有额外的内存ordering 参数）
    - `memory_order_seq_cst`  严格顺序一致
    - release 到 之后的acquire 之间，会创建一个 happens before edge。release类似与unlock ，acquire类似于 lock，在release 之前的write 对于acquire之后的子序列一定是可见的，就像执行在unlock一个mutex的写一定会被给相同mutex的上锁后的read 看见
    
    ```
    atomic_store(&done, 1, memory_order_release);
    // code
    while(atomic_load(&done, memory_order_acquire) == 0) { /* loop */ }
    
    ```
    
    - 强弱的atomic有什么区别？首先顺序一致性 要求所有的原子操作 在total ordering的角度看来是完全一致的，但是acquire/release 做不到。weak seq 只能要求单个内存位置上操作的顺序一致的交互，因此weak 只有连贯性，即对一个内存地址 比如x 的两次read，不会在不同处理器上 一个读出 12  另一个读出 21
    - 因而，当程序使用超过一个内存地址时，程序中的所有acq/rel 原子量 从观察程序执行的角度来看，不满足顺序一致性的要求，也就是违反了DRF-SC
- 重来来看store buffering 的例子：Litmus Test: Store BufferingCan this program see r1 = 0, r2 = 0?

```
// Thread 1           // Thread 2
x = 1                 y = 1
r1 = y                r2 = x
On sequentially consistent hardware: no.
On x86 (or other TSO): yes!
On ARM/POWER: yes!
On Java (using volatiles): no.
On C++11 (sequentially consistent atomics): no.
On C++11 (acquire/release atomics): yes!
```

- strong 和weak 创建出来的 happens before edge 时先相同的，不同之处在于，weak 会允许出现一些 strong 不允许出现的read结果，如上述例子
- 【宽松原子量】
- 和ordinary readwrite 没有任何区别，除了在宽松原子量出现数据竞争时，不会被当作race 也不会遭殃

### C、Rust、Swift 内存模型

- 三者和C++11 的内存模型一样，使用DRF-SC 或者 Catch Fire 以及所有的原子类型和原子fence
- 毕竟编译器都是C/C++ 的编译器工具链

# 总结

- 上边的最后一个代码例子 是个很好的例子
- 所有的编程语言都为并行程序提供了顺序一致性的同步原子量
- 所有的编程语言也都旨在使用正确的同步行为来使得DRF，像单线程顺序执行的行为一样
- Java引入了acq rel 的weak 同步原子，想要在data race的情况下定义程序行为，显然会有很多复杂情况，直到Java 9引入了VarHandle
- 还会有ordinary value，啥都没有的，有data race 就有，不care